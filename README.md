# PROJECT IN YOUR FEELS

Our project is to explore using our application to understand accuracy in classifying human facial expressions from images.
Primary dataset used for this project was taken from face++, YouTube API/Google developer.
Emotion Detection â€” Classifying the emotion on the face as angry, happy, sad, disgusted and surprised.

The technologies that we used - 
AJAX
Bootstrap
Face ++ API
YouTube API/Google Developer
Google Font

Methodology- 

Start-> Read Sentences from Dataset -> sentence preprocessing -> Pharsal Verb Identification -> Emotion Keyword Analysis ->
Intenstiy Check -> Negation Check -> Defines Emotion Youtube Video ->End

Future Development-

-update software to allow our application to read the emotions on a human face using advanced image processing.
- create a window to display the scene capture by web camera and a window representing the probabilites of defected emtions.





